# Gesture-control
Gesture-based computer control using Python, OpenCV, MediaPipe, and PyAutoGUI. Tracks hand landmarks via webcam to enable mouse movement, left/right clicks, and gesture-based control. Supports real-time interaction with intuitive finger gestures, providing a hands-free way to navigate and control the system


ğŸ–ï¸ Gesture Control Project
This project implements a gesture-based computer control system using Python, OpenCV, MediaPipe, and PyAutoGUI. By tracking hand landmarks in real-time through a webcam, it enables mouse movement, left/right clicks, and gesture-based interactions, providing a hands-free way to control your computer.

ğŸ“Œ Features
ğŸ‘† Move Mouse Cursor â€“ Control cursor by moving your index and middle fingers.

ğŸ–±ï¸ Left Click â€“ Triggered when the index finger is lowered while the middle finger is raised.

ğŸ–±ï¸ Right Click â€“ Triggered when the middle finger is lowered while the index finger is raised.

âœ‹ Stop Mouse Movement â€“ Raise your pinky finger to stop the cursor from moving.

ğŸ¥ Real-time Hand Tracking â€“ Powered by MediaPipe Hand Landmarks for accurate gesture recognition.

ğŸ› ï¸ Tech Stack
Python 3.x

OpenCV â€“ For image processing & webcam input

MediaPipe â€“ For real-time hand tracking

PyAutoGUI â€“ For simulating mouse actions

âš™ï¸ Installation
Clone the repository:

git clone https://github.com/your-username/gesture-control-project.git
cd gesture-control-project
Install required dependencies:

pip install opencv-python mediapipe pyautogui
Run the project:

python gesture_control_project.py
ğŸ® How It Works
The webcam captures live video.

MediaPipe detects and tracks hand landmarks.

Gestures are interpreted based on finger positions:

Index Up + Middle Up â†’ Move mouse

Index Down + Middle Up â†’ Left Click

Middle Down + Index Up â†’ Right Click

Pinky Up â†’ Pause cursor movement

ğŸ“Š Use Cases
Hands-free navigation for accessibility

Alternative input system for gaming and interactive applications

Prototype for gesture-based HCI (Human-Computer Interaction) research

ğŸš€ Future Improvements
Add scrolling gestures (two-finger swipe)

Integrate multi-hand tracking

Support for custom gesture training

Add voice + gesture hybrid control
